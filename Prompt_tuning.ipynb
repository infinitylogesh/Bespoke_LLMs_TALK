{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt Tuning - NL2SQL using Santacoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/logesh_umapathi/miniconda3/envs/llama_4bit/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Found cached dataset wikisql (/mnt/data/logesh/hf_cache/wikisql/default/0.1.0/7037bfe6a42b1ca2b6ac3ccacba5253b1825d31379e9cc626fc79a620977252d)\n",
      "100%|██████████████████████████████████████████████████████████████████████| 3/3 [00:00<00:00, 353.15it/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"wikisql\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'phase': 1,\n",
       " 'question': 'Tell me what the notes are for South Australia ',\n",
       " 'table': {'header': ['State/territory',\n",
       "   'Text/background colour',\n",
       "   'Format',\n",
       "   'Current slogan',\n",
       "   'Current series',\n",
       "   'Notes'],\n",
       "  'page_title': '',\n",
       "  'page_id': '',\n",
       "  'types': ['text', 'text', 'text', 'text', 'text', 'text'],\n",
       "  'id': '1-1000181-1',\n",
       "  'section_title': '',\n",
       "  'caption': '',\n",
       "  'rows': [['Australian Capital Territory',\n",
       "    'blue/white',\n",
       "    'Yaa·nna',\n",
       "    'ACT · CELEBRATION OF A CENTURY 2013',\n",
       "    'YIL·00A',\n",
       "    'Slogan screenprinted on plate'],\n",
       "   ['New South Wales',\n",
       "    'black/yellow',\n",
       "    'aa·nn·aa',\n",
       "    'NEW SOUTH WALES',\n",
       "    'BX·99·HI',\n",
       "    'No slogan on current series'],\n",
       "   ['New South Wales',\n",
       "    'black/white',\n",
       "    'aaa·nna',\n",
       "    'NSW',\n",
       "    'CPX·12A',\n",
       "    'Optional white slimline series'],\n",
       "   ['Northern Territory',\n",
       "    'ochre/white',\n",
       "    'Ca·nn·aa',\n",
       "    'NT · OUTBACK AUSTRALIA',\n",
       "    'CB·06·ZZ',\n",
       "    'New series began in June 2011'],\n",
       "   ['Queensland',\n",
       "    'maroon/white',\n",
       "    'nnn·aaa',\n",
       "    'QUEENSLAND · SUNSHINE STATE',\n",
       "    '999·TLG',\n",
       "    'Slogan embossed on plate'],\n",
       "   ['South Australia',\n",
       "    'black/white',\n",
       "    'Snnn·aaa',\n",
       "    'SOUTH AUSTRALIA',\n",
       "    'S000·AZD',\n",
       "    'No slogan on current series'],\n",
       "   ['Victoria',\n",
       "    'blue/white',\n",
       "    'aaa·nnn',\n",
       "    'VICTORIA - THE PLACE TO BE',\n",
       "    'ZZZ·562',\n",
       "    'Current series will be exhausted this year']],\n",
       "  'name': 'table_1000181_1'},\n",
       " 'sql': {'human_readable': 'SELECT Notes FROM table WHERE Current slogan = SOUTH AUSTRALIA',\n",
       "  'sel': 5,\n",
       "  'agg': 0,\n",
       "  'conds': {'column_index': [3],\n",
       "   'operator_index': [0],\n",
       "   'condition': ['SOUTH AUSTRALIA']}}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, default_data_collator, get_linear_schedule_with_warmup\n",
    "from peft import get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, TaskType, PeftType\n",
    "import torch\n",
    "from datasets import load_dataset\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "\n",
    "device = \"cuda\"\n",
    "model_name_or_path = \"bigcode/santacoder\"\n",
    "tokenizer_name_or_path = \"bigcode/santacoder\"\n",
    "peft_config = PromptTuningConfig(\n",
    "    task_type=TaskType.CAUSAL_LM,\n",
    "    prompt_tuning_init=PromptTuningInit.TEXT,\n",
    "    num_virtual_tokens=8,\n",
    "    prompt_tuning_init_text=\"Convert question in natural language to SQL\",\n",
    "    tokenizer_name_or_path=model_name_or_path,\n",
    ")\n",
    "\n",
    "\n",
    "text_column = \"question\"\n",
    "label_column = \"human_readable\"\n",
    "max_length = 64\n",
    "lr = 3e-2\n",
    "num_epochs = 3\n",
    "batch_size = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "if tokenizer.pad_token_id is None:\n",
    "    tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting wikisql to instruction dataset\n",
    "\n",
    "```Format: Question : <Question> \\n Table Columns : <List_of_columns> \\n SQL : <SQL_TO_BE_GENERATED>```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_table_context(table):\n",
    "    header_type = [f\"{header}:{typ}\" for header,typ in zip(table['header'],table['types'])]\n",
    "    return \",\".join(header_type)\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    batch_size = len(examples[text_column])\n",
    "    inputs = [f\"{text_column} : {x} \\n Table Columns : {fetch_table_context(t)} \\n SQL : \" for x,t in zip(examples[text_column],examples['table'])] \n",
    "    print(inputs[0])\n",
    "    targets = [str(x[label_column])+'\\n' for x in examples[\"sql\"]]\n",
    "    model_inputs = tokenizer(inputs)\n",
    "    labels = tokenizer(targets)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i] + [tokenizer.pad_token_id]\n",
    "        # print(i, sample_input_ids, label_input_ids)\n",
    "        model_inputs[\"input_ids\"][i] = sample_input_ids + label_input_ids\n",
    "        labels[\"input_ids\"][i] = [-100] * len(sample_input_ids) + label_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [1] * len(model_inputs[\"input_ids\"][i])\n",
    "    # print(model_inputs)\n",
    "    for i in range(batch_size):\n",
    "        sample_input_ids = model_inputs[\"input_ids\"][i]\n",
    "        label_input_ids = labels[\"input_ids\"][i]\n",
    "        model_inputs[\"input_ids\"][i] = [tokenizer.pad_token_id] * (\n",
    "            max_length - len(sample_input_ids)\n",
    "        ) + sample_input_ids\n",
    "        model_inputs[\"attention_mask\"][i] = [0] * (max_length - len(sample_input_ids)) + model_inputs[\n",
    "            \"attention_mask\"\n",
    "        ][i]\n",
    "        labels[\"input_ids\"][i] = [-100] * (max_length - len(sample_input_ids)) + label_input_ids\n",
    "        model_inputs[\"input_ids\"][i] = torch.tensor(model_inputs[\"input_ids\"][i][:max_length])\n",
    "        model_inputs[\"attention_mask\"][i] = torch.tensor(model_inputs[\"attention_mask\"][i][:max_length])\n",
    "        labels[\"input_ids\"][i] = torch.tensor(labels[\"input_ids\"][i][:max_length])\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:   2%|▍                        | 1000/56355 [00:00<00:15, 3642.70 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Tell me what the notes are for South Australia  \n",
      " Table Columns : State/territory:text,Text/background colour:text,Format:text,Current slogan:text,Current series:text,Notes:text \n",
      " SQL : \n",
      "question : What is the number for years 1985-88 \n",
      " Table Columns : Player:text,No.:real,Nationality:text,Position:text,Years for Jazz:text,School/Club Team:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:   5%|█▎                       | 3000/56355 [00:00<00:14, 3586.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the barrel length for a cold model le6921sp? \n",
      " Table Columns : Colt model no.:text,Name:text,Stock:text,Fire control:text,Rear sight:text,Forward assist:text,Barrel length:text,Barrel profile:text,Barrel twist:text,Hand guards:text,Bayonet Lug:text,Muzzle device:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:   7%|█▊                       | 4000/56355 [00:01<00:13, 3753.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : what amount of try bonus where the game was won by 11? \n",
      " Table Columns : Club:text,Played:text,Won:text,Drawn:text,Lost:text,Points for:text,Points against:text,Tries for:text,Tries against:text,Try bonus:text,Losing bonus:text,Points:text \n",
      " SQL : \n",
      "question : What is the highest value of PF when Ends Lost is 51? \n",
      " Table Columns : Locale:text,Skip:text,W:real,L:real,PF:real,PA:real,Ends Won:real,Ends Lost:real,Blank Ends:real,Stolen Ends:real,Shot Pct.:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:  11%|██▋                      | 6000/56355 [00:01<00:13, 3657.15 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : How many times is a score for stolen ends recorded for France? \n",
      " Table Columns : Country:text,Skip:text,W:real,L:real,PF:real,PA:real,Ends Won:real,Ends Lost:real,Blank Ends:real,Stolen Ends:real,Shot %:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  12%|███                      | 7000/56355 [00:01<00:13, 3653.25 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : How many seasons did \"strangled, not stirred\" air? \n",
      " Table Columns : No. in series:real,No. in season:real,Title:text,Directed by:text,Written by:text,Original air date:text,Production code:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  14%|███▌                     | 8000/56355 [00:02<00:14, 3278.42 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What's team #2 in the round where team $1 is Ilisiakos? \n",
      " Table Columns : Team #1:text,Agg. score:text,Team #2:text,1st leg:text,2nd leg:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  16%|███▉                     | 9000/56355 [00:02<00:13, 3483.29 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the total of countys where Obama is popular by 35.44%? \n",
      " Table Columns : County:text,Obama%:text,Obama#:real,McCain%:text,McCain#:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  18%|████▎                   | 10000/56355 [00:02<00:13, 3562.94 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Who is the head coach for the score of 4-3? \n",
      " Table Columns : Tournament:real,Conference:text,Championship Game Opponent:text,Score:text,Location:text,Head Coach:text \n",
      " SQL : \n",
      "question : How did the game number 50 end? \n",
      " Table Columns : Game:real,Date:text,Team:text,Score:text,High points:text,High rebounds:text,High assists:text,Location Attendance:text,Record:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:  21%|█████                   | 12000/56355 [00:03<00:12, 3534.52 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : How many individuals watched the show that had a bbc ranking of 6? \n",
      " Table Columns : Episode no.:real,Airdate:text,Viewers:text,BBC Three weekly ranking:text,Cable rank:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  23%|█████▌                  | 13000/56355 [00:03<00:11, 3668.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : what are all the state/nation where the race number is 36 \n",
      " Table Columns : Position:real,Race number:text,Sail number:text,Yacht:text,State/country:text,Yacht type:text,LOA (Metres):text,Skipper:text,Elapsed time d:hh:mm:ss:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  25%|█████▉                  | 14000/56355 [00:04<00:12, 3368.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the Galician (reintegrationist) word of the Galician (Official) is adeus*? \n",
      " Table Columns : English:text,Galician ( Official ):text,Galician ( Reintegrationist ):text,Portuguese:text,Spanish:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  27%|██████▍                 | 15000/56355 [00:04<00:11, 3542.10 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the production code for the episode that had 23.9 million u.s. viewers? \n",
      " Table Columns : No. in series:real,No. in season:real,Title:text,Directed by:text,Written by:text,Original air date:text,Production code:real,U.S. viewers (millions):text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  28%|██████▊                 | 16000/56355 [00:04<00:11, 3466.06 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the year listed when tied is listed as 11? \n",
      " Table Columns : Year:text,Position:real,Games played:real,Won:real,Tied:real,Lost:real,Goals Scored:real,Goals Against:real,Points:real,Postseason place:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  30%|███████▏                | 17000/56355 [00:04<00:11, 3338.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : How many weeks have an attendance of 64,116? \n",
      " Table Columns : Week:real,Date:text,Opponent:text,Result:text,Venue:text,Attendance:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  32%|███████▋                | 18000/56355 [00:05<00:10, 3574.13 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : In which venue did 0 pens and 1 try occur? \n",
      " Table Columns : Player:text,Tries:text,Conv:text,Pens:text,Drop:text,Venue:text,Date:text \n",
      " SQL : \n",
      "question : On what date is Hawthorn the home team? \n",
      " Table Columns : Home team:text,Home team score:text,Away team:text,Away team score:text,Venue:text,Crowd:real,Date:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:  35%|████████▌               | 20000/56355 [00:05<00:10, 3613.02 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Which Result has a Score of 4-1, and a Competition of world cup qualifying? \n",
      " Table Columns : Date:text,Result:text,Score:text,Brazil scorers:text,Competition:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  37%|████████▉               | 21000/56355 [00:05<00:09, 3856.41 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What's the lowest Floors with Feet that's larger htan 262, has a Name of Standard Bank Building, and Metres that's larger htan 138.8? \n",
      " Table Columns : Name:text,City:text,Years as tallest:text,Metres:real,Feet:real,Floors:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  39%|█████████▎              | 22000/56355 [00:06<00:09, 3504.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Which Outcome has a Score of 6–4, 2–6, 6–3? \n",
      " Table Columns : Outcome:text,Date:text,Tournament:text,Surface:text,Opponent:text,Score:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  41%|█████████▊              | 23000/56355 [00:06<00:08, 3737.28 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Which Operator has a Width of 2.65 m, and a Type designation of m5000? \n",
      " Table Columns : City:text,Operator:text,Type designation:text,Number of vehicles:real,Width:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  43%|██████████▏             | 24000/56355 [00:06<00:08, 3818.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the score of the game that 33,531 people went too? \n",
      " Table Columns : Date:text,Opponent:text,Score:text,Loss:text,Attendance:text,Record:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  44%|██████████▋             | 25000/56355 [00:07<00:08, 3504.95 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : For which song was the score 6.5 + 6.0 + 6.0 + 5.5 = 24.0? \n",
      " Table Columns : Index:text,Name:text,Song:text,Group Song:text,Score:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  46%|███████████             | 26000/56355 [00:07<00:08, 3752.73 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Which nation's total is less than 19 when there's less than 1 bronze? \n",
      " Table Columns : Rank:text,Nation:text,Gold:real,Silver:real,Bronze:real,Total:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  48%|███████████▍            | 27000/56355 [00:07<00:07, 3787.68 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the first locomotive that has a SLM number lower than 924? \n",
      " Table Columns : Built:real,Number:real,Type:text,SLM Number:real,Wheel arrangement:text,Location:text,Notes:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  50%|███████████▉            | 28000/56355 [00:07<00:08, 3535.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the largest amount of top division titles featuring the tammeka club? \n",
      " Table Columns : Club:text,Position in 2012:text,First season in top division:real,Number of seasons in Meistriliiga:real,First season of current spell in top division:real,Top division titles:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  51%|████████████▎           | 29000/56355 [00:08<00:07, 3674.16 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What was the top score for grier jones? \n",
      " Table Columns : Place:text,Player:text,Country:text,Score:real,To par:text \n",
      " SQL : \n",
      "question : What is the average pick for Princeton after round 3? \n",
      " Table Columns : Round:real,Pick:real,Player:text,Nationality:text,College:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:  55%|█████████████▏          | 31000/56355 [00:08<00:06, 3641.06 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is richard virenque's lowest rank? \n",
      " Table Columns : Rank:real,Name:text,Country:text,Wins:real,Years:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  57%|█████████████▋          | 32000/56355 [00:08<00:06, 3736.20 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the average number of matches of leonardo in seasons after 1? \n",
      " Table Columns : Name:text,Seasons:real,Matches:real,Win %:text,Draw:real,Draw %:text,Lose:real,Lose %:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  59%|██████████████          | 33000/56355 [00:09<00:06, 3479.27 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the Area of the Parish with a Population of 2,113? \n",
      " Table Columns : Official Name:text,Status:text,Area km 2:real,Population:real,Census Ranking:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  60%|██████████████▍         | 34000/56355 [00:09<00:06, 3668.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the highest number of rebounds of the game with a 6-14 record? \n",
      " Table Columns : Game:real,Date:text,Opponent:text,Score:text,High points:text,High rebounds:text,High assists:text,Location/Attendance:text,Record:text \n",
      " SQL : \n",
      "question : Who is the 2nd round opponent when Team 2 is Red Star (D1)? \n",
      " Table Columns : Team 1:text,Score:text,Team 2:text,1st round:text,2nd round:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:  64%|███████████████▎        | 36000/56355 [00:10<00:05, 3494.07 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What class had 1 made and fleet number of 406? \n",
      " Table Columns : Class:text,Wheel arrangement:text,Fleet number(s):text,Manufacturer:text,Year made:text,Quantity made:text,Quantity preserved:text \n",
      " SQL : \n",
      "question : what is the event for the year less than 1913 with the position of 2nd? \n",
      " Table Columns : Year:real,Competition:text,Venue:text,Position:text,Event:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  66%|███████████████▊        | 37000/56355 [00:10<00:05, 3824.35 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What Constructor had 66 Laps? \n",
      " Table Columns : Driver:text,Constructor:text,Laps:real,Time/Retired:text,Grid:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:  69%|████████████████▌       | 39000/56355 [00:10<00:04, 3611.99 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Name the polyunsaturated fat with a saturated fat of 25g \n",
      " Table Columns : Total fat:text,Saturated fat:text,Monounsaturated fat:text,Polyunsaturated fat:text,Smoke point:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  71%|█████████████████       | 40000/56355 [00:11<00:04, 3793.78 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What away team plays at Victoria Park? \n",
      " Table Columns : Home team:text,Home team score:text,Away team:text,Away team score:text,Venue:text,Crowd:real,Date:text \n",
      " SQL : \n",
      "question : What was Collingwood's score at the home match against Richmond? \n",
      " Table Columns : Home team:text,Home team score:text,Away team:text,Away team score:text,Venue:text,Crowd:real,Date:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:  75%|█████████████████▉      | 42000/56355 [00:11<00:03, 3699.83 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : On waht date did Antoinette Jeanne Yvonne Boegner get married? \n",
      " Table Columns : Name:text,Birth:text,Marriage:text,Became Duke:text,Ceased to be Duke:text,Death:text,Spouse:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  76%|██████████████████▎     | 43000/56355 [00:12<00:03, 3818.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : When the Away team score equaled 15.20 (110) what was the Date of the game? \n",
      " Table Columns : Home team:text,Home team score:text,Away team:text,Away team score:text,Venue:text,Crowd:real,Date:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  78%|██████████████████▋     | 44000/56355 [00:12<00:03, 3523.91 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is Party, when Results is \"Re-Elected\", when First Elected is greater than 1990, and when District is \"Minnesota 4\"? \n",
      " Table Columns : District:text,Incumbent:text,Party:text,First elected:real,Results:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  80%|███████████████████▏    | 45000/56355 [00:12<00:03, 3660.51 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Who is the winner in des moines, iowa where p.h. finkbank was the runner-up? \n",
      " Table Columns : Year:text,Winner:text,Runner-up:text,Venue:text,Location:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  82%|███████████████████▌    | 46000/56355 [00:12<00:02, 3850.90 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Which Score has a To par of –3, and a Player of santiago luna? \n",
      " Table Columns : Place:text,Player:text,Country:text,Score:real,To par:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  83%|████████████████████    | 47000/56355 [00:13<00:02, 3521.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What 8:00 am has a 3:00 pm of space goofs (mon) spider-man (tue-fri)? \n",
      " Table Columns : 7:00 am:text,7:30 am:text,8:00 am:text,9:00 am:text,11:00 am:text,noon:text,12:30 pm:text,1:00 pm:text,1:30 pm:text,2:00 pm:text,3:00 pm:text,4:30 pm:text,5:00 pm:text,6:30 pm:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  85%|████████████████████▍   | 48000/56355 [00:13<00:02, 3649.09 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the height for the 2008 club Arona? \n",
      " Table Columns : Name:text,Height:text,Weight:text,Spike:text,2008 club:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  87%|████████████████████▊   | 49000/56355 [00:13<00:01, 3795.12 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the team when the college is virginia tech? \n",
      " Table Columns : Pick:real,Team:text,Player:text,Position:text,College:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  89%|█████████████████████▎  | 50000/56355 [00:14<00:01, 3351.60 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the latest year the world championships were held in Thun? \n",
      " Table Columns : Year:real,Place:text,Gold:text,Silver:text,Bronze:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  90%|█████████████████████▋  | 51000/56355 [00:14<00:01, 3421.74 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : How many picks on average did Jay Bruchak have before round 6? \n",
      " Table Columns : Round:real,Pick:real,Player:text,Nationality:text,College:text \n",
      " SQL : \n",
      "question : Result of 1st, and a Venue of melbourne , australia, and a Extra of 100 m happened in which year? \n",
      " Table Columns : Year:real,Tournament:text,Venue:text,Result:text,Extra:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:  94%|██████████████████████▌ | 53000/56355 [00:14<00:00, 3525.96 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the highest Isolation (km) when the elevation was smaller than 1320, and a Municipality of hinnøya? \n",
      " Table Columns : Peak:text,Elevation (m):real,Prominence (m):real,Isolation (km):real,Municipality:text,County:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  96%|██████████████████████▉ | 54000/56355 [00:15<00:00, 3697.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What's the Total for a Mexico City game with a Gold of less than 4 and a Bronze of less than 2? \n",
      " Table Columns : Year:text,Edition:text,Host city:text,Gold:real,Silver:real,Bronze:real,Total:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  98%|███████████████████████▍| 55000/56355 [00:15<00:00, 3369.50 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Name the average apps for smederevo \n",
      " Table Columns : Season:text,Team:text,Country:text,Division:real,Apps:real,Goals:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  99%|███████████████████████▊| 56000/56355 [00:15<00:00, 3578.88 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What was Olin Dutra's score? \n",
      " Table Columns : Place:text,Player:text,Country:text,Score:text,To par:text,Money ( $ ):text \n",
      " SQL : \n",
      "question : Name the power for 1.8 duratorq \n",
      " Table Columns : Model/Engine:text,Capacity:text,Cylinders/Valves:text,Power/rpm:text,Torque (Nm)/rpm:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:   6%|█▌                       | 1000/15878 [00:00<00:03, 3990.84 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is terrence ross' nationality \n",
      " Table Columns : Player:text,No.:text,Nationality:text,Position:text,Years in Toronto:text,School/Club Team:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  13%|███▏                     | 2000/15878 [00:00<00:04, 2920.18 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Who is the director of the episode that corresponds to the total episodes number 14?  \n",
      " Table Columns : Total#:real,Series#:real,Title:text,Writer:text,Director:text,Original air date:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  19%|████▋                    | 3000/15878 [00:00<00:03, 3250.14 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the black caribbean population when the other black population is 2243? \n",
      " Table Columns : Rank:real,London Borough:text,Black African Population:real,Black Caribbean Population:real,Other Black Population:real,Total Black Population:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  25%|██████▎                  | 4000/15878 [00:01<00:03, 3060.75 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : How many votes for brown in the place that had 84.1% for coakley? \n",
      " Table Columns : Municipality:text,Coakley votes:real,Coakley %:text,Brown votes:real,Brown %:text,Kennedy votes:real,Kennedy %:text,Total vote:real,Turnout %:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  31%|███████▊                 | 5000/15878 [00:01<00:03, 3203.34 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the production code for episode 96 in the series? \n",
      " Table Columns : No. in series:text,No. in season:text,Title:text,Directed by:text,Written by:text,Original air date:text,Production code:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  38%|█████████▍               | 6000/15878 [00:01<00:03, 3069.63 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Which Slalom has a Giant Slalom of 8? \n",
      " Table Columns : Season:real,Overall:real,Slalom:text,Giant Slalom:text,Super G:text,Downhill:text,Combined:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  44%|███████████              | 7000/15878 [00:02<00:02, 3370.80 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Rank of 5, and a Silver larger than 0 had what sum of total? \n",
      " Table Columns : Rank:text,Nation:text,Gold:real,Silver:real,Bronze:real,Total:real \n",
      " SQL : \n",
      "question : Who is the professional partner of celebrity małgorzata foremniak with a season less than 7, an average greater than 34.66, and a rank less than 10? \n",
      " Table Columns : Rank:real,Celebrity:text,Professional Partner:text,Season:real,Average:real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on dataset:  57%|██████████████▏          | 9000/15878 [00:02<00:01, 3573.32 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Who was the opponent when he went more than 1 round with a record of 12-7? \n",
      " Table Columns : Res.:text,Record:text,Opponent:text,Method:text,Event:text,Round:real,Time:text,Location:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  63%|███████████████         | 10000/15878 [00:02<00:01, 3774.72 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the area in km2 for the community that had a population in 2011 larger than 35,916 and a density of less than 47.1 inhabitants/km 2? \n",
      " Table Columns : Name:text,Seat:text,Population (2011):real,Area (km 2 ):real,Density (inhabitants/km 2 ):real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  69%|████████████████▋       | 11000/15878 [00:03<00:01, 3469.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the lowest Game, when Opponent is \"Boston Bruins\"? \n",
      " Table Columns : Game:real,March:real,Opponent:text,Score:text,Record:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  76%|██████████████████▏     | 12000/15878 [00:03<00:01, 3598.53 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Tell me the winning driver for jim clark as pole position and fastest lap \n",
      " Table Columns : Race:text,Circuit:text,Date:text,Pole position:text,Fastest lap:text,Winning driver:text,Constructor:text,Tyre:text,Report:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  82%|███████████████████▋    | 13000/15878 [00:03<00:00, 3712.01 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : Which site has the CERCLIS ID fld004092532? \n",
      " Table Columns : CERCLIS ID:text,Name:text,County:text,Partially deleted:text,Deleted:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  88%|█████████████████████▏  | 14000/15878 [00:04<00:00, 3304.89 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What country is Steve Jones from? \n",
      " Table Columns : Place:text,Player:text,Country:text,Score:text,To par:text,Money ( $ ):real \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Running tokenizer on dataset:  94%|██████████████████████▋ | 15000/15878 [00:04<00:00, 3370.49 examples/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the lowest number of f/laps with more than 4 podiums and more than 14 races? \n",
      " Table Columns : Season:real,Series:text,Team:text,Races:real,Wins:real,Poles:real,F/Laps:real,Podiums:real,Points:real,Position:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What Golden point(s) scorer has the Away Brisbane Broncos and Home South Sydney Rabbitohs? \n",
      " Table Columns : Home:text,Score:text,Away:text,Venue:text,Golden point(s) scorer:text \n",
      " SQL : \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "train_processed_datasets = dataset['train'].map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    load_from_cache_file=False,\n",
    "    remove_columns=dataset[\"train\"].column_names,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")\n",
    "\n",
    "test_processed_datasets = dataset['test'].map(\n",
    "    preprocess_function,\n",
    "    batched=True,\n",
    "    num_proc=1,\n",
    "    load_from_cache_file=False,\n",
    "    remove_columns=dataset[\"test\"].column_names,\n",
    "    desc=\"Running tokenizer on dataset\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "    train_processed_datasets, shuffle=True, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True\n",
    ")\n",
    "eval_dataloader = DataLoader(test_processed_datasets, collate_fn=default_data_collator, batch_size=batch_size, pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Explicitly passing a `revision` is encouraged when loading a configuration with custom code to ensure no malicious code has been contributed in a newer revision.\n",
      "Explicitly passing a `revision` is encouraged when loading a model with custom code to ensure no malicious code has been contributed in a newer revision.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 16384 || all params: 1124902912 || trainable%: 0.0014564812505348018\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = AutoModelForCausalLM.from_pretrained(model_name_or_path,trust_remote_code=True)\n",
    "model = get_peft_model(model, peft_config)\n",
    "print(model.print_trainable_parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.AdamW(model.parameters(), lr=lr)\n",
    "lr_scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=(len(train_dataloader) * num_epochs),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 7045/7045 [39:53<00:00,  2.94it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████| 1985/1985 [05:24<00:00,  6.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0: train_ppl=tensor(1.3023, device='cuda:0') train_epoch_loss=tensor(0.2641, device='cuda:0') eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████| 7045/7045 [40:05<00:00,  2.93it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 1985/1985 [05:27<00:00,  6.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=1: train_ppl=tensor(nan, device='cuda:0') train_epoch_loss=tensor(nan, device='cuda:0') eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████| 7045/7045 [40:11<00:00,  2.92it/s]\n",
      "100%|████████████████████████████████████████████████████████████| 1985/1985 [05:26<00:00,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=2: train_ppl=tensor(nan, device='cuda:0') train_epoch_loss=tensor(nan, device='cuda:0') eval_ppl=tensor(nan, device='cuda:0') eval_epoch_loss=tensor(nan, device='cuda:0')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = model.to(device)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for step, batch in enumerate(tqdm(train_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        total_loss += loss.detach().float()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    model.eval()\n",
    "    eval_loss = 0\n",
    "    eval_preds = []\n",
    "    for step, batch in enumerate(tqdm(eval_dataloader)):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        eval_loss += loss.detach().float()\n",
    "        eval_preds.extend(\n",
    "            tokenizer.batch_decode(torch.argmax(outputs.logits, -1).detach().cpu().numpy(), skip_special_tokens=True)\n",
    "        )\n",
    "\n",
    "    eval_epoch_loss = eval_loss / len(eval_dataloader)\n",
    "    eval_ppl = torch.exp(eval_epoch_loss)\n",
    "    train_epoch_loss = total_loss / len(train_dataloader)\n",
    "    train_ppl = torch.exp(train_epoch_loss)\n",
    "    print(f\"{epoch=}: {train_ppl=} {train_epoch_loss=} {eval_ppl=} {eval_epoch_loss=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./prompt_model\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Which Frequency is used for WEGP calls?',\n",
       " 'Calls:text,Frequency:text,Branding:text,Format:text,Market/Rank:text,Timeslot:text,Group owner:text')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "dataset['test'][40]['question'], fetch_table_context(dataset['test'][40]['table'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer(model,input_text):\n",
    "    inputs = tokenizer(input_text,return_tensors=\"pt\")\n",
    "    with torch.no_grad():\n",
    "        inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "        outputs = model.generate(\n",
    "            input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], max_new_tokens=40, eos_token_id=stop_words_ids[0])\n",
    "    \n",
    "    return tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)\n",
    "\n",
    "def parse(text):\n",
    "    return text.split(\"SQL :\")[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:185 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " SELECT AVG score FROM table WHERE subject = maths\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_text = \"\"\"question : What is the average score of students in maths \n",
    " Table Columns : id:INT,name:text,subject:Text,score:INT\n",
    " SQL : \"\"\"\n",
    " \n",
    "predictions = infer(model,input_text)\n",
    "print(parse(predictions[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question : What is the average score of students in maths \n",
      " Table Columns : id:INT,name:text,subject:Text,score:INT\n",
      " SQL : SELECT AVG score FROM table WHERE subject = maths\n",
      "t.println(result\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_4bit",
   "language": "python",
   "name": "llama_4bit"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
